{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grade: /100 pts\n",
    "\n",
    "# Assignment 05: Model Selection & Cross Validation\n",
    "\n",
    "### Dear Applicant...You've Been Invited To  Interview To Be A Data Scientist!\n",
    "\n",
    "You've been invited to interview for a Junior Data Scientist job for a professional football (er, Soccer) club.  The owner of the team is very interested in seeing how the use of data can help improve the team's peformance, and perhaps win them the next national championship!\n",
    "\n",
    "The draft is coming up soon (thats when you get to pick new players for your team). To test your skills, the owner has asked you to create a model to help score potential draftees.  The model should look at attributes about the player and predict what their \"rating\" will be once they start playing professionally.\n",
    "\n",
    "The football club's data team has provided you with data for 17,993 footballers from the league.  Your job: build a model or models, perform model selection, and make predictions on players you have not yet seen.\n",
    "\n",
    "### The Dataset\n",
    "\n",
    "The data is stored in a csv file called `footballer_data.csv`.  The data contain 52 columns, including some information about the player, their skills, and their overall measure as an effective footballer.\n",
    "\n",
    "Most features relate to the player's abilities in football related skills, such as passing, shooting, dribbling, etc.  Some features are rated on a 1-5 scale (5 being the best), others are rated on 0-100 (100 being the best), and others still are categorical (e.g. work rate is coded as low, medium, or high).\n",
    "\n",
    "The target variable (or $y$ variable, if you will) is `overall`.  This is an overall measure of the footballer's skill and is rated from 0 to 100.  The most amazingly skilled footballer would be rated 100, where as I would struggle to score more than a 20. The model(s) you build should use the other features to predict `overall`.\n",
    "\n",
    "\n",
    "### Follow These Steps before submitting\n",
    "Once you are finished, ensure to complete the following steps.\n",
    "\n",
    "1.  Restart your kernel by clicking 'Kernel' > 'Restart & Run All'.\n",
    "\n",
    "2.  Fix any errors which result from this.\n",
    "\n",
    "3.  Repeat steps 1. and 2. until your notebook runs without errors.\n",
    "\n",
    "4.  Submit your completed notebook to OWL by the deadline.\n",
    "\n",
    "\n",
    "### Preliminaries\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: /10pts\n",
    "\n",
    "The hiring manager is going to walk you through a data analysis.  Your job is to implement what they ask to showcase yous skills as a data scientist.\n",
    "\n",
    "Read in the data and take a look at the dataframe.  There should be 52 columns. The outcome of interest is called `overall` which gives an overall measure of player performance. Not all of the other columns are particularly useful for modelling though (for instance, `ID` is just a unique identifier for the player.  This is essentially an arbitrary number and has no bearing on the player's rating).\n",
    "\n",
    "The hiring manager tells you to remove the following columns:\n",
    "\n",
    "* ID\n",
    "* club\n",
    "* club_logo\n",
    "* birth_date\n",
    "* flag\n",
    "* nationality\n",
    "* photo\n",
    "* potential\n",
    "\n",
    "The hiring manager would also like the following columns converted into dummy variables:\n",
    "\n",
    "* work_rate_att\n",
    "* work_rate_def\n",
    "* preferred_foot\n",
    "\n",
    "Clean the data according to the hiring manager's instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>overall</th>\n",
       "      <th>pac</th>\n",
       "      <th>sho</th>\n",
       "      <th>pas</th>\n",
       "      <th>dri</th>\n",
       "      <th>def</th>\n",
       "      <th>phy</th>\n",
       "      <th>international_reputation</th>\n",
       "      <th>skill_moves</th>\n",
       "      <th>weak_foot</th>\n",
       "      <th>crossing</th>\n",
       "      <th>finishing</th>\n",
       "      <th>heading_accuracy</th>\n",
       "      <th>short_passing</th>\n",
       "      <th>volleys</th>\n",
       "      <th>dribbling</th>\n",
       "      <th>curve</th>\n",
       "      <th>free_kick_accuracy</th>\n",
       "      <th>long_passing</th>\n",
       "      <th>ball_control</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>sprint_speed</th>\n",
       "      <th>agility</th>\n",
       "      <th>reactions</th>\n",
       "      <th>balance</th>\n",
       "      <th>shot_power</th>\n",
       "      <th>jumping</th>\n",
       "      <th>stamina</th>\n",
       "      <th>strength</th>\n",
       "      <th>long_shots</th>\n",
       "      <th>aggression</th>\n",
       "      <th>interceptions</th>\n",
       "      <th>positioning</th>\n",
       "      <th>vision</th>\n",
       "      <th>penalties</th>\n",
       "      <th>composure</th>\n",
       "      <th>marking</th>\n",
       "      <th>standing_tackle</th>\n",
       "      <th>work_rate_att_Medium</th>\n",
       "      <th>work_rate_att_High</th>\n",
       "      <th>work_rate_def_Medium</th>\n",
       "      <th>work_rate_def_High</th>\n",
       "      <th>preferred_foot_Right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>185.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>94</td>\n",
       "      <td>90</td>\n",
       "      <td>93</td>\n",
       "      <td>82</td>\n",
       "      <td>90</td>\n",
       "      <td>33</td>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>94</td>\n",
       "      <td>88</td>\n",
       "      <td>83</td>\n",
       "      <td>88</td>\n",
       "      <td>91</td>\n",
       "      <td>81</td>\n",
       "      <td>76</td>\n",
       "      <td>77</td>\n",
       "      <td>93</td>\n",
       "      <td>89</td>\n",
       "      <td>91</td>\n",
       "      <td>89</td>\n",
       "      <td>96</td>\n",
       "      <td>63</td>\n",
       "      <td>94</td>\n",
       "      <td>95</td>\n",
       "      <td>92</td>\n",
       "      <td>80</td>\n",
       "      <td>92</td>\n",
       "      <td>63</td>\n",
       "      <td>29</td>\n",
       "      <td>95</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>95</td>\n",
       "      <td>22</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>170.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>93</td>\n",
       "      <td>89</td>\n",
       "      <td>90</td>\n",
       "      <td>86</td>\n",
       "      <td>96</td>\n",
       "      <td>26</td>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>77</td>\n",
       "      <td>95</td>\n",
       "      <td>71</td>\n",
       "      <td>88</td>\n",
       "      <td>85</td>\n",
       "      <td>97</td>\n",
       "      <td>89</td>\n",
       "      <td>90</td>\n",
       "      <td>87</td>\n",
       "      <td>95</td>\n",
       "      <td>92</td>\n",
       "      <td>87</td>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>85</td>\n",
       "      <td>68</td>\n",
       "      <td>73</td>\n",
       "      <td>59</td>\n",
       "      <td>88</td>\n",
       "      <td>48</td>\n",
       "      <td>22</td>\n",
       "      <td>93</td>\n",
       "      <td>90</td>\n",
       "      <td>78</td>\n",
       "      <td>96</td>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>175.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>84</td>\n",
       "      <td>79</td>\n",
       "      <td>95</td>\n",
       "      <td>30</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>75</td>\n",
       "      <td>89</td>\n",
       "      <td>62</td>\n",
       "      <td>81</td>\n",
       "      <td>83</td>\n",
       "      <td>96</td>\n",
       "      <td>81</td>\n",
       "      <td>84</td>\n",
       "      <td>75</td>\n",
       "      <td>95</td>\n",
       "      <td>94</td>\n",
       "      <td>90</td>\n",
       "      <td>96</td>\n",
       "      <td>88</td>\n",
       "      <td>82</td>\n",
       "      <td>80</td>\n",
       "      <td>61</td>\n",
       "      <td>78</td>\n",
       "      <td>53</td>\n",
       "      <td>77</td>\n",
       "      <td>56</td>\n",
       "      <td>36</td>\n",
       "      <td>90</td>\n",
       "      <td>80</td>\n",
       "      <td>81</td>\n",
       "      <td>92</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>182.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>92</td>\n",
       "      <td>82</td>\n",
       "      <td>90</td>\n",
       "      <td>79</td>\n",
       "      <td>87</td>\n",
       "      <td>42</td>\n",
       "      <td>81</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>77</td>\n",
       "      <td>94</td>\n",
       "      <td>77</td>\n",
       "      <td>83</td>\n",
       "      <td>88</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>84</td>\n",
       "      <td>64</td>\n",
       "      <td>91</td>\n",
       "      <td>88</td>\n",
       "      <td>77</td>\n",
       "      <td>86</td>\n",
       "      <td>93</td>\n",
       "      <td>60</td>\n",
       "      <td>87</td>\n",
       "      <td>69</td>\n",
       "      <td>89</td>\n",
       "      <td>80</td>\n",
       "      <td>86</td>\n",
       "      <td>78</td>\n",
       "      <td>41</td>\n",
       "      <td>92</td>\n",
       "      <td>84</td>\n",
       "      <td>85</td>\n",
       "      <td>83</td>\n",
       "      <td>30</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>193.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>92</td>\n",
       "      <td>91</td>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>89</td>\n",
       "      <td>60</td>\n",
       "      <td>91</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>25</td>\n",
       "      <td>55</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>59</td>\n",
       "      <td>48</td>\n",
       "      <td>58</td>\n",
       "      <td>61</td>\n",
       "      <td>52</td>\n",
       "      <td>85</td>\n",
       "      <td>35</td>\n",
       "      <td>25</td>\n",
       "      <td>78</td>\n",
       "      <td>44</td>\n",
       "      <td>83</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>70</td>\n",
       "      <td>47</td>\n",
       "      <td>70</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  height_cm  weight_kg  overall  pac  sho  pas  dri  def  phy  \\\n",
       "0   32      185.0       80.0       94   90   93   82   90   33   80   \n",
       "1   30      170.0       72.0       93   89   90   86   96   26   61   \n",
       "2   25      175.0       68.0       92   92   84   79   95   30   60   \n",
       "3   30      182.0       86.0       92   82   90   79   87   42   81   \n",
       "4   31      193.0       92.0       92   91   90   95   89   60   91   \n",
       "\n",
       "   international_reputation  skill_moves  weak_foot  crossing  finishing  \\\n",
       "0                         5            5          4        85         94   \n",
       "1                         5            4          4        77         95   \n",
       "2                         5            5          5        75         89   \n",
       "3                         5            4          4        77         94   \n",
       "4                         5            1          4        15         13   \n",
       "\n",
       "   heading_accuracy  short_passing  volleys  dribbling  curve  \\\n",
       "0                88             83       88         91     81   \n",
       "1                71             88       85         97     89   \n",
       "2                62             81       83         96     81   \n",
       "3                77             83       88         86     86   \n",
       "4                25             55       11         30     14   \n",
       "\n",
       "   free_kick_accuracy  long_passing  ball_control  acceleration  sprint_speed  \\\n",
       "0                  76            77            93            89            91   \n",
       "1                  90            87            95            92            87   \n",
       "2                  84            75            95            94            90   \n",
       "3                  84            64            91            88            77   \n",
       "4                  11            59            48            58            61   \n",
       "\n",
       "   agility  reactions  balance  shot_power  jumping  stamina  strength  \\\n",
       "0       89         96       63          94       95       92        80   \n",
       "1       90         95       95          85       68       73        59   \n",
       "2       96         88       82          80       61       78        53   \n",
       "3       86         93       60          87       69       89        80   \n",
       "4       52         85       35          25       78       44        83   \n",
       "\n",
       "   long_shots  aggression  interceptions  positioning  vision  penalties  \\\n",
       "0          92          63             29           95      85         85   \n",
       "1          88          48             22           93      90         78   \n",
       "2          77          56             36           90      80         81   \n",
       "3          86          78             41           92      84         85   \n",
       "4          16          29             30           12      70         47   \n",
       "\n",
       "   composure  marking  standing_tackle  work_rate_att_Medium  \\\n",
       "0         95       22               31                     0   \n",
       "1         96       13               28                     1   \n",
       "2         92       21               24                     0   \n",
       "3         83       30               45                     0   \n",
       "4         70       10               10                     1   \n",
       "\n",
       "   work_rate_att_High  work_rate_def_Medium  work_rate_def_High  \\\n",
       "0                   1                     0                   0   \n",
       "1                   0                     1                   0   \n",
       "2                   1                     1                   0   \n",
       "3                   1                     1                   0   \n",
       "4                   0                     1                   0   \n",
       "\n",
       "   preferred_foot_Right  \n",
       "0                     1  \n",
       "1                     0  \n",
       "2                     1  \n",
       "3                     1  \n",
       "4                     1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('footballer_data.csv')\n",
    "\n",
    "# Drop the aformentioned columns\n",
    "model_data = df.drop(['ID','club','club_logo','flag', 'nationality','photo','potential', 'birth_date'], axis = 'columns')\n",
    "\n",
    "# In order to get dummies, you can convert the categorical data to categorical type\n",
    "# with a specific \n",
    "model_data['work_rate_att'] = pd.Categorical(model_data.work_rate_att, categories=['Low','Medium','High'])\n",
    "model_data['work_rate_def'] = pd.Categorical(model_data.work_rate_def, categories=['Low','Medium','High'])\n",
    "model_data['preferred_foot'] = pd.Categorical(model_data.preferred_foot, categories = ['Left','Right'])\n",
    "\n",
    "# Dummies, dropping the first category\n",
    "model_data = pd.get_dummies(model_data, drop_first=True)\n",
    "\n",
    "model_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: /10 pts\n",
    "\n",
    "The data should all be numerical now. To evalute different models, the hiring manager asks you to define a function that returns the mean squared error. \n",
    "\n",
    "*\"Before we begin modelling, it is important to obtain a baseline for the accuracy of our predictive models.\"* says the hiring manager. *Compute the squared errors resulting if we use the mean of the `overall` variable to make predictions. Then compute the expected loss. This will serve as our baseline performance.*\n",
    "\n",
    "Plot the distribution of the losses (squared errors) and print their mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.254360338508775 68.68075613538082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'count')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define mean squared error function  \n",
    "def mse(ytrue,ypred):\n",
    "    return np.power(ytrue - ypred,2).mean()\n",
    "\n",
    "# Get mean and Std \n",
    "sample_mean = model_data.overall.mean()\n",
    "mu = mse(model_data.overall, sample_mean )\n",
    "loss = np.power(model_data.overall - sample_mean, 2)\n",
    "sigma = loss.std(ddof=1)\n",
    "print(mu, sigma)\n",
    "\n",
    "# Plot distribution  \n",
    "plt.hist(loss);\n",
    "plt.xlabel('squared error')\n",
    "plt.ylabel('count')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: /15pts\n",
    "\n",
    "To prepare the data for modelling, the hiring manager asks you use `sklearn.model_selection.train_test_split` to seperate the data into a training set and a test set.\n",
    "\n",
    "The hiring manager would like you to estimate the performance of the final selected model to within +/- 0.25 units using mean squared error as the loss function of choice.  You remember that you can use the formula for effective test size to accomplish this.\n",
    "\n",
    "The formula for the effective test size is\n",
    "\n",
    "$$ n = \\left(\\frac{1.96 \\sigma_l}{d}\\right)^2$$\n",
    "\n",
    "Can you estimate the performance of the model to within their desired precsion? Why or why not?  If you can't, tell the hiring manager why you can't and then tell them what precision splitting the data into 50% train and 50% test will achieve.\n",
    "\n",
    "Include your answer as if you were writing the hiring manager an email in a markdown cell below..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Hey Hiring Manager,\n",
    "\n",
    "You asked me to estimate the number of samples needed to estimate the final model performance to within +/- 0.25. That would require ... almost 290, 000 data points.  I'm afraid we just don't have the sample size to achieve this.\n",
    "\n",
    "If I were to split the training set into 50% test and 50% train, I could estimate the model performance to within +/- 1.4.  I'm going to go ahead and use a 50% train test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We don't have enough data\n",
      "Using a 50/50 split gives us a precision of 1.4\n",
      "(8997, 45) (8997, 45)\n"
     ]
    }
   ],
   "source": [
    "# Need rationale or sample size\n",
    "# Need an estimate for sigma \n",
    "# Use sigma from previous question\n",
    "\n",
    "d = 0.25 #Provided from question\n",
    "\n",
    "test_size = (2*sigma/d)**2\n",
    "\n",
    "if test_size<df.shape[0]:\n",
    "    print(\"We've got enough data\")\n",
    "else:\n",
    "    print(\"We don't have enough data\")\n",
    "    test_size = 0.5\n",
    "    achieved_precision = (2*sigma/np.sqrt(8997))\n",
    "    print(f\"Using a 50/50 split gives us a precision of {achieved_precision:.2}\")\n",
    "\n",
    "y = model_data.overall\n",
    "X = model_data.drop('overall', axis = 'columns')\n",
    "\n",
    "# Random state assures that folds are consistent across models\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X,\n",
    "                                                y, \n",
    "                                                test_size = test_size, \n",
    "                                                random_state = 0)\n",
    "\n",
    "print(Xtrain.shape,Xtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: /5pts\n",
    "The team at the football clib use sklearn to build a model pipelines for their projects. To learn more about pipelines, do lab section 5.9 (lab part 2) and read up on sklearn pipelines [here](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html). \n",
    "\n",
    "The hiring manager want you to create a model pipeline to be fit later.  Create an sklearn pipeline which fits a linear regression model.  Don't fit the data yet!  The hiring manager will tell you when to do that...\n",
    "\n",
    "Note that the sklearn linear regression adds its own intercept so you don't need to create a column of 1s.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Pipeline([\n",
    "    ('linear_regression', LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: /15pts\n",
    "\n",
    "The hiring manager wants you to perform cross validation on the model you constructed in the last question.  They want to make sure you understand what cross validation is, so they've asked you to **write your own function to do cross validation.  Do not use sklearn's functions to do this for you.  Else, you won't get the job!**.\n",
    "\n",
    "\n",
    "Your function should take the following arguments:\n",
    "\n",
    "* `model` -- an instance of an sklearn pipeline (like the one you made in the last question)\n",
    "* `X` -- a matrix of features\n",
    "* `y` -- a vector of outcomes (remember we're using the \"overall\" column from the data)\n",
    "* `cv` -- an integer no smaller than 1 and no larger than 10.  This represents the number of folds to make in the cross validation step.\n",
    "* `scoring` -- a loss function.  \n",
    "\n",
    "Your function should return:\n",
    "\n",
    "* cv_scores -- an array of length `cv`.  This houses the cross validation estimates from each fold.\n",
    "\n",
    "Perform 5 fold cross validation with your function.  Report the estimated average mean square error from your cross validation.\n",
    "\n",
    "Note: Please make sure you write your own function to perform crossvalidation. While you can use sklearn's `cross_val_score` the main aim of this question is to test that you have a thorough understanding of cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.8203651691248215"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cross_validate(model, X, y, cv, scoring_function):\n",
    "    \n",
    "    np.random.seed(0)\n",
    "    \n",
    "    num_samples, num_featues = X.shape\n",
    "    \n",
    "    # Uniformly sample fold IDs.  Every observation needs to belong to a fold.\n",
    "    # Add 1 to CV else numpy will sample between 1 and cv-1.\n",
    "    \n",
    "    folds = np.random.randint(low = 1, high = cv+1, size = num_samples)\n",
    "\n",
    "    # Initialize somewhere to hold the scores.\n",
    "    cv_scores = np.zeros(cv)\n",
    "\n",
    "    for i, fold in enumerate(np.unique(folds)):\n",
    "        # Determine which observations we are going to leave in/out\n",
    "        holdout_ix = folds==fold\n",
    "        train_ix = folds!=fold\n",
    "\n",
    "        # Fit the model on the ones we leave in\n",
    "        model.fit(X[train_ix], y[train_ix])\n",
    "        # Predict on the ones we leave out\n",
    "        ypred = model.predict(X[holdout_ix])\n",
    "        \n",
    "        # Record the score in the array\n",
    "        cv_scores[i] = scoring_function(y[holdout_ix], ypred)\n",
    "\n",
    "    return cv_scores\n",
    "    \n",
    "cross_validate(model1, Xtrain, ytrain, cv = 5, scoring_function = mean_squared_error).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation Estimate: 5.82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6: /15pts\n",
    "\n",
    "That's impressive!  Your model seems to be very accurate, but now the hiring manager wants to try and make it more accurate.  They share with you that scounts see that players hit their prime in their late 20s, and as they age they become worse overall.  Thus, the effect of age seems to increase at first and then start to decrease.  Kind of like a quadratic funciton.\n",
    "\n",
    "The hiring manager wants you to add a quadratic term for age to the model.  Repeat the steps above (creating a pipeline, validating the model, etc) for a model which includes a quadratic term for age. As in the Lab, include the addition of the quadratic term for Age as a Transform into the pipeline. Report the cross validated performance below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.71522848007633"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model2 with costum transform (You can also use ColumnTransformer)\n",
    "class Age2(BaseEstimator,TransformerMixin):  \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X,y=None):\n",
    "        X = X.assign(age2 = X.age**2)\n",
    "        return X\n",
    "\n",
    "model2 = Pipeline([\n",
    "    ('age2', Age2()),\n",
    "    ('linear_regression', LinearRegression())\n",
    "])\n",
    "\n",
    "\n",
    "#Using the code from question5\n",
    "cross_validate(model2, Xtrain, ytrain, cv = 5, scoring_function = mean_squared_error).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation Estimate: 5.72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.715228480076328"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is another way using ColumnTransformer\n",
    "# ColumnTransformer is a way to apply transforms to single columns or groups of columns\n",
    "# without having to manually engineer the new feature.  It works a lot like Pipeline.\n",
    "# This is nice because we can pass our raw data and not have to worry about computing the correct feature\n",
    "# This sounds silly for something as easy as squaring a column, but when your features become more complex\n",
    "# this becomes very useful\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Using PolynomialFeatures to square the age column.\n",
    "# The tuple looks like ('name_of_step', Transformer, ['column_you_want_to_transform'])\n",
    "list_of_transforms = [('square_age', PolynomialFeatures(include_bias=False, interaction_only=False), ['age'])]\n",
    "\n",
    "#remainder='passthrough' means that untransformed features are left alone and are not altered or thrown away.  Very important!!!\n",
    "ct = ColumnTransformer(list_of_transforms, remainder='passthrough')\n",
    "\n",
    "#Inclide as a part of our pipeline\n",
    "model2 = Pipeline([\n",
    "    ('column_transformer', ct),\n",
    "    ('linear_regression', LinearRegression())\n",
    "])\n",
    "\n",
    "# Now get CV-error using code from Q5 \n",
    "cross_validate(model2, Xtrain, ytrain, cv = 5, scoring_function = mean_squared_error).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7: /10 pts\n",
    "\n",
    "\n",
    "Hmmm...You aren't happy that the quadratic age  term has not improved the fit of the model.  You *really* want to impress the hiring manager, and decide to add more features to your model in hopes it will improve performance. \n",
    "\n",
    "Add sklearn's `PolynomialFeatures` to your pipeline from question 5 and set `degree=2`. Cross validate the new model and report the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4816869666227777"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=2,include_bias = False)),\n",
    "    ('linear_regression', LinearRegression())\n",
    "])\n",
    "\n",
    "cross_validate(model3, Xtrain, ytrain, cv = 5, scoring_function = mean_squared_error).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation Estimate: 1.48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8: /10pts\n",
    "\n",
    "Great job!  You've managed to decrease the loss by a lot!  The hiring manager is really impressed with your work and things are looking good for your employment status!  \n",
    "\n",
    "However, the hiring manager is a little too happy with your peformance.  The hiring manager wants to explore third order interactions (that is adding cubic terms to the model).  The hiring manager tells you that their super computers can handle the computation; \"*It's no big deal for us*\" they boast.\n",
    " \n",
    "This is not a good idea, and you know it!  Talk them out of doing this.  Write them an email in the cell below explaining what could happen if you add too may interactions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hey Hiring Manager,\n",
    "\n",
    "I got your email about adding cubic terms to the model.  I think...adding cubic terms to the model will likely overfit the data.  If we add cubic terms, then the number of predictors will be very close to the number of observations.  This will make it easy for us to get a low training error, but will likely not generalize very well. It is my recomendation that we NOT add cubic terms.\n",
    "\n",
    "Sincerly,\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9:  /10pts\n",
    "\n",
    "You've successfully talked the hiring manager out of adding cubic terms to the model. Good job!  Now the hiring manager asks for your opinion.  Over the course of the interview, you've fit three models.  It is time to pick a model to deploy!\n",
    "\n",
    "Based on the cross validation scores, which model would you choose?  \n",
    "Train your chosen model on all the training data. \n",
    "Estimate the performance of your chosen model on the test data you held out, and do the following:\n",
    "\n",
    "- Compute a point estimate for the generalization error. (A \"point estimate\" is a single number that we expect to be close to the thing we are trying to estimate.)\n",
    "- Compute a confidence interval for the generalization error.  \n",
    "- Plot the distribution of the squared errors.\n",
    "\n",
    "Is the test error close to the cross validation error of the model you chose? Why do you think this is the case? Answer below as if you were talking to the hiring manager.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hey Hiring Manager,\n",
    "\n",
    "Because model 3 had the smallest cross validation error, I would pick model 3.  After fitting the model on all the training data, model 3 has a test error of 1.44 (confidence interval 1.38 -- 1.50).  That is pretty close to our cross validated error, which means we haven't overfit on the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalization Error:  1.4452414306117676\n",
      "Confidence interval:  [1.38561064 1.50487222]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit our best performing model on all the training data\n",
    "model3.fit(Xtrain, ytrain)\n",
    "\n",
    "#Predict on the test set\n",
    "ypred = model3.predict(Xtest)\n",
    "\n",
    "#Compute the errors and a point estimate of the generalization error\n",
    "test_errors = np.power(ytest - ypred, 2)\n",
    "generalization_error = test_errors.mean()\n",
    "\n",
    "#Construct a confidence interval\n",
    "# We have enough data in our test set that the appropirate t-quantile is close to 1.96\n",
    "test_ci = generalization_error + 1.96 * np.std(test_errors) / np.sqrt(len(test_errors)) * np.array([-1, 1])\n",
    "\n",
    "plt.hist(test_errors)\n",
    "plt.xlabel('squared error')\n",
    "plt.ylabel('count')\n",
    "\n",
    "print('Generalization Error: ',generalization_error)\n",
    "print('Confidence interval: ', test_ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follow These Steps before submitting\n",
    "Once you are finished, ensure to complete the following steps.\n",
    "\n",
    "1.  Restart your kernel by clicking 'Kernel' > 'Restart & Run All'.\n",
    "\n",
    "2.  Fix any errors which result from this.\n",
    "\n",
    "3.  Repeat steps 1. and 2. until your notebook runs without errors.\n",
    "\n",
    "4.  Submit your completed notebook to OWL by the deadline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
